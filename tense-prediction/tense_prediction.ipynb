{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tense prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from estnltk import Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tere', 'estnltk']\n"
     ]
    }
   ],
   "source": [
    "print( Text('Tere estnltk').lemmas )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with codecs.open(DATA_DIR+\"cleaned-tc-tok-train.en\", \"r\", \"utf8\") as f:\n",
    "    en = [line.strip() for line in f]\n",
    "with codecs.open(DATA_DIR+\"cleaned-tc-tok-train.et\", \"r\", \"utf8\") as f:\n",
    "    et = [line.strip() for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000667 16000667\n"
     ]
    }
   ],
   "source": [
    "print(len(en), len(et))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grep for future tense markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = re.compile(\"(.*)((will)|(&apos;ll)|(won &apos;t)|((am|is|are|&apos;re|&apos;s|&apos;m)( not)? (going to|gonna)))\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find all matched strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.asarray([1 if re.match(pattern, string) else 0 for string in en])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "766440"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"train_future_labels.en\", \"w\") as f:\n",
    "    f.writelines([str(l) for l in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"train_future_labels.en\", \"r\") as f:\n",
    "    labels = np.array([int(i) for i in f.read()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select equal number of future tense strings and other:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CLASS_SIZE = min(400000, np.sum(labels))\n",
    "CLASS_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400000 400000\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "ind_fut = np.random.choice(np.where(labels == 1)[0], CLASS_SIZE)\n",
    "ind_oth = np.random.choice(np.where(labels == 0)[0], CLASS_SIZE)\n",
    "print(len(ind_fut), len(ind_oth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check matched sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 'we &apos;ll pay the usual premium for tradesmen and fertile women , et cetera .',\n",
       "       'ECB staff will then make the photocopies .',\n",
       "       'it &apos;s gonna happen .',\n",
       "       'we &apos;re not quite in Vegas yet , but we &apos;ll get there eventually .',\n",
       "       'I &apos;m gonna pin it on him .', 'I &apos;m going to bed .',\n",
       "       'as regards third-party documents , the CIS will consult the third party concerned before proceeding to carry out the declassification .',\n",
       "       'right , then maybe we &apos;ll make some of our money back for filming this .',\n",
       "       'we &apos;re trying to work out a schedule of the outfits we &apos;re gonna play this year .',\n",
       "       'this will help the EU get back onto the path of economic growth by fostering scientific excellence and research , underpinning innovation and increasing the attractiveness of the EU as a research location .',\n",
       "       'if , in an off-premises contract , the goods , by their nature , cannot normally be returned by post and have been delivered to the consumer &apos;s home at the time of the conclusion of the contract : ‘ We will collect the goods at our own expense . ’ &#93;',\n",
       "       'I am gonna make myself some tea .',\n",
       "       'that . it &apos;ll knock out any doll in a ten-foot radius , Including a pesky sleeper like cindy ,',\n",
       "       'we regret that His Highness will be unable to see you .',\n",
       "       'we &apos;ll get you over to your venue and pick up some dim sum on the way .',\n",
       "       'the Giant hogweed eradication campaign in Belgium , for example , will be undermined if the species reinvades from France .',\n",
       "       '- I &apos;ll get out .',\n",
       "       'Marge , this time I &apos;m gonna give you the wedding deserve .',\n",
       "       'but it would be pointless to let the EU institutions waste time and energy on proposals which have no chance of being adopted – that will not deliver the results we want to see on the ground .',\n",
       "       'I am therefore convinced that we must introduce control mechanisms that will prevent the managers of investment and hedge funds from making ill-judged analyses of operational and systemic risks .'],\n",
       "      dtype='<U684')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matched = np.array([en[i] for i in ind_fut])\n",
    "matched[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800000 800000\n"
     ]
    }
   ],
   "source": [
    "X = np.concatenate([np.array([et[i] for i in ind_fut]), np.array([et[i] for i in ind_oth])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.concatenate([labels[ind_fut], labels[ind_oth]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X), len(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatize everything except verbs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(sent):\n",
    "    text = Text(sent)\n",
    "    return ' '.join([text.lemmas[i].split('|')[0]  # Take lemma\n",
    "                     if pt.split('|')[0] != 'V'    # if word is not a verb\n",
    "                     else text.word_texts[i]       # else take the verb itself\n",
    "                     for i, pt in enumerate(text.postags)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'maksame tavapärane tasu kaupmees ja viljakas naine eest ...'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatize(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemX = np.array([lemmatize(s) for s in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lemX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"lemmatized_800k.et\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(lemX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"lemmatized_800k.et\", \"r\") as f:\n",
    "    lemX = np.array([s.strip() for s in f])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Dense, Input, Flatten\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding, Merge, Dropout, LSTM, GRU, Bidirectional\n",
    "from keras.models import Model, load_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer, InputSpec\n",
    "from keras import initializers\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 1000\n",
    "MAX_NB_WORDS = 30000\n",
    "EMBEDDING_DIM = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 193610 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(lemX)\n",
    "sequences = tokenizer.texts_to_sequences(lemX)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving\n",
    "with open('tokenizer_400k.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading\n",
    "with open('tokenizer_400k.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (800000, 1000)\n",
      "Shape of label tensor: (800000, 2)\n"
     ]
    }
   ],
   "source": [
    "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "y = to_categorical(y)\n",
    "print('Shape of data tensor:', data.shape)\n",
    "print('Shape of label tensor:', y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, y, test_size=0.2, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 1000, 100)         19361100  \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 200)               160800    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 402       \n",
      "=================================================================\n",
      "Total params: 19,522,302\n",
      "Trainable params: 19,522,302\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "l_lstm = Bidirectional(LSTM(units=EMBEDDING_DIM, recurrent_dropout=0.2, dropout=0.4))(embedded_sequences)\n",
    "preds = Dense(2, activation='softmax')(l_lstm)\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])\n",
    "\n",
    "# checkpoint\n",
    "filepath=\"lstm_fut_binary_model_400k_adam_dropout02-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"lstm_fut_binary_model_400k_adam_dropout02-00-0.82.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 512000 samples, validate on 128000 samples\n",
      "Epoch 1/4\n",
      "511744/512000 [============================>.] - ETA: 3s - loss: 0.3895 - acc: 0.8273Epoch 00000: val_acc improved from -inf to 0.82445, saving model to lstm_fut_binary_model_400k_adam_dropout02-00-0.82.hdf5\n",
      "512000/512000 [==============================] - 7164s - loss: 0.3894 - acc: 0.8273 - val_loss: 0.3952 - val_acc: 0.8244\n",
      "Epoch 2/4\n",
      "511744/512000 [============================>.] - ETA: 3s - loss: 0.3589 - acc: 0.8429Epoch 00001: val_acc improved from 0.82445 to 0.82734, saving model to lstm_fut_binary_model_400k_adam_dropout02-01-0.83.hdf5\n",
      "512000/512000 [==============================] - 6897s - loss: 0.3589 - acc: 0.8429 - val_loss: 0.3941 - val_acc: 0.8273\n",
      "Epoch 3/4\n",
      "511744/512000 [============================>.] - ETA: 3s - loss: 0.3424 - acc: 0.8510Epoch 00002: val_acc improved from 0.82734 to 0.82824, saving model to lstm_fut_binary_model_400k_adam_dropout02-02-0.83.hdf5\n",
      "512000/512000 [==============================] - 6873s - loss: 0.3424 - acc: 0.8510 - val_loss: 0.3964 - val_acc: 0.8282\n",
      "Epoch 4/4\n",
      "511744/512000 [============================>.] - ETA: 3s - loss: 0.3247 - acc: 0.8599Epoch 00003: val_acc improved from 0.82824 to 0.82875, saving model to lstm_fut_binary_model_400k_adam_dropout02-03-0.83.hdf5\n",
      "512000/512000 [==============================] - 6889s - loss: 0.3247 - acc: 0.8599 - val_loss: 0.4000 - val_acc: 0.8287\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    validation_split=0.2, \n",
    "    callbacks=callbacks_list,\n",
    "    shuffle=True,\n",
    "    epochs=4, \n",
    "    batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.training.Model at 0x7f237a393358>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('lstm_fut_binary_model_48k_adam_dropout02.h5')\n",
    "\n",
    "with open('lstm_fut_model_48k_adam_dropout02_def.json','w') as ff:\n",
    "    json_string = model.to_json()\n",
    "    ff.write(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(history):\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.savefig('./accuracy_curve.png')\n",
    "    plt.clf()\n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.savefig('./loss_curve.png')\n",
    "\n",
    "plot_learning_curve(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBRERSVAoiIhIgkJBREQSFAoiIpLw/wF74f6gx9PyIQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7facf003f518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting on test data\n",
      "0.82735\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Predicting on test data')\n",
    "y_pred = np.rint(model.predict(X_test))\n",
    "\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[67290 12513]\n",
      " [15111 65086]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_test[:,0], y_pred[:,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Misclassified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_positive = np.intersect1d(np.where(y_pred == 1), np.where(y_test == 0))\n",
    "false_negative = np.intersect1d(np.where(y_pred == 0), np.where(y_test == 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Krahmer report A6-0046 / 2009 — Amendment 5 / 2', 'go !',\n",
       "       '~ Gosh ! they smell so good . ~ Yeah !',\n",
       "       'the Court considers , however , that grants should be awarded on the basis of Commission decisions since , according to the Financial Regulation , the use of the Commission decision procedure is a pre-condition for agreeing on negotiated flat rates for indirect costs , established according to the usual cost accounting practices of the participant , over and above the 7 % established by the Financial Regulation ( see paragraphs 69 and 70 ) .',\n",
       "       '15 .',\n",
       "       '( 11a ) In accordance with the objectives of the Community Action Plan on the Protection and Welfare of Animals ( 2006 – 2010 ) the Commission should endeavour to promote the welfare of animals used for scientific purposes internationally , and in particular to seek promotion of the replacement , reduction and refinement of animal procedures through the World Organisation for Animal Health ( OIE ) , and by seeking to add animal welfare standards to the criteria assessed in order to establish compliance with Good Laboratory Practice ( GLP ) .',\n",
       "       'what are you talking about ?',\n",
       "       'look , just relax . we &apos;ll get her back .',\n",
       "       '- There had to be something else .',\n",
       "       'I told you this Greece thing was gonna be great .',\n",
       "       '- Hey , come on , man , where you going ? - Chill , partner .',\n",
       "       'name of the applicant and the stamp of the applicant .',\n",
       "       'it &apos;s a 25-year-old bottle of Takagi .',\n",
       "       'must have been internal or something .',\n",
       "       'you have done nothing but be an invaluable advisor to me and an even better friend .',\n",
       "       'Hi .', 'she &apos;s gone .',\n",
       "       'according to the tax laws of a Member State is considered to be resident in that Member State for tax purposes and , under the terms of a double taxation agreement concluded with a third country , is not considered to be resident for tax purposes outside the Community ; and',\n",
       "       '- I don &apos;t want to go fishing .',\n",
       "       'you know the rules , Lai Lai .'],\n",
       "      dtype='<U795')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp = en[false_positive]\n",
    "fp[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estonian sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split by clauses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PresText(Text):\n",
    "\n",
    "    def __init__(self, sentence):\n",
    "        Text.__init__(self, sentence)\n",
    "        self.present_indices = self.present_ind()\n",
    "        self.clauses_with_present = self.clauses_present()\n",
    "\n",
    "    def present_ind(self):\n",
    "        present_tags = ['b', 'd', 'ge', 'gem', 'gu', 'ks', 'ksid', 'ksime', 'ksin', 'ksite', 'me', 'n', 'neg ge',\n",
    "                        'neg gem', 'neg gu', 'neg ks', 'meg me', 'neg o', 'neg vat', 'o', 'ta', 'tagu', 'taks',\n",
    "                        'takse', 'tav', 'tavat', 'te', 'v', 'vad', 'vat']\n",
    "        return [i for i, t in enumerate(self.get.forms.as_list[0]) if t in present_tags]\n",
    "\n",
    "    def clauses_present(self):\n",
    "        clauses_present = [self.clause_texts[j] for j in [self.clause_indices[i] for i in self.present_indices]]\n",
    "        return clauses_present"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
